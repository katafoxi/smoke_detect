####################################################################################################
# SPDX-FileCopyrightText: Copyright (c) 2022-2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: LicenseRef-NvidiaProprietary
#
# NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
# property and proprietary rights in and to this material, related
# documentation and any modifications thereto. Any use, reproduction,
# disclosure or distribution of this material and related documentation
# without an express license agreement from NVIDIA CORPORATION or
# its affiliates is strictly prohibited.
####################################################################################################

#ABBREVIATURES
#GIE - GPU Inference Engine Механизм вывода графического процессора
#DLA - Deep Learning Accelerator Ускоритель глубокого обучения
#IOU tracking algorithm
#ROI Область интереса


# https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_using_custom_model.html#cuda-engine-creation-for-custom-models
## спецификация https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvinfer.html#gst-nvinfer-file-configuration-specifications
## Группа настраивает общее поведение плагина. Это единственная обязательная группа. 
property:

  #############################################################################
  #____________________ NET TYPES
  #############################################################################

  ##**(All, Both, Integer, ) Режим (первичный или вторичный), в котором должен работать элемент (игнорируется, если включен input-tensor-meta). 
  # 1=Primary, 
  # 2=Secondary
  process-mode: 1

  ##**(All, Both, Integer) Тип сети
  # 0: Detector
  # 1: Classifier
  # 2: Segmentation
  # 3: Instance Segmentation
  #network-type: 2

  ##(All, Both, Integer, >0) Уникальный идентификатор, который будет присвоен GIE, чтобы приложение и другие элементы могли идентифицировать обнаруженные ограничивающие рамки и метки.
  gie-unique-id: 1

  ##(All, Both, Integer, >0) Уникальный идентификатор GIE, с метаданными которого (ограничивающими рамками) этот GIE должен работать.
  operate-on-gie-id: 1



  #############################################################################
  #_________________________ HARDWARE
  #############################################################################

  ## Идентификатор устройства графического процессора, который будет использоваться для предварительной обработки/вывода (только для dGPU)
  gpu-id: 0

  ##(All, Both, Integer) Вычислить аппаратное обеспечение, которое будет использоваться для масштабирования кадров/обрезок объектов до разрешения сети (игнорируется, если включен входной тензорный мета)
  # 0: Platform default – GPU (dGPU), VIC (Jetson) 
  # 1: GPU 
  # 2: VIC (Jetson only)
  scaling-compute-hw: 2

  ##(All, Both, Boolean) Указывает, использовать ли механизм DLA для вывода. Примечание. DLA поддерживается только на NVIDIA® Jetson AGX Orin™ и NVIDIA® Jetson Orin NX™. В настоящее время работа продолжается.
  enable-dla: 0

  ##(All, Both, Integer, ≥0) Используемое ядро ​​DLA. Примечание. Поддерживается только на Jetson AGX Orin и Jetson Orin NX. В настоящее время работа продолжается.
  use-dla-core: 0



  #############################################################################
  #_________________________INPUT
  #############################################################################
  ##(All, Both, Integer, ) Цветовой формат, требуемый моделью (игнорируется, если включен input-tensor-meta)
  # 0:RGB, 
  # 1:BGR, 
  # 2:GRAY
  model-color-format: 0


  ##(All, Both, Integer) Порядок входного слоя сети (игнорируется, если включен input-tensor-meta)
  # 0:NCHW партия N , каналы C , глубина D , высота H , ширина W
  # 1:NHWC
  network-input-order: 0

  ##(All, Both, Integer, >0) Количество кадров или объектов, которые будут выводиться вместе в пакете
  batch-size: 1

  ##(All, Both, Boolean) Если сеть поддерживает как неявное пакетное измерение, так и полное измерение, принудительно включите режим неявного пакетного измерения.
  force-implicit-batch-dim: 1

  # Странная хрень, в спецификации property отсутствует
  ##(all, both) Привязка размеров для установки на входном слое изображения.
  ## https://forums.developer.nvidia.com/t/what-does-infer-dims-do/160717/3
  infer-dims: 3;512;512

  ##(All, Both, Float, >0.0) Коэффициент нормализации пикселей (игнорируется, если включен входной тензорный мета)
  net-scale-factor: 0.031

  ##(All, Both, Semicolon delimited float array, all values ≥0) Массив средних значений компонентов цвета, которые необходимо вычесть из каждого пикселя. Длина массива должна равняться количеству цветовых компонентов в кадре. Плагин умножает средние значения на коэффициент чистого масштабирования. (игнорируется, если включен входной тензорный мета)
  #offsets=77.5;21.2;11.8
  #offsets: 127.5; 127.5; 127.5
  offsets: 120.0;122.7;119.6

  ##(All, Both, Boolean) Указывает, следует ли сохранять соотношение сторон при масштабировании ввода.
  maintain-aspect-ratio: 0

  ##(All, Both, Boolean) Указывает, следует ли дополнять изображение симметрично при масштабировании ввода. По умолчанию DeepStream дополняет изображения асимметрично.
  symmetric-padding: 1

  ##(All, Primary, Boolean) Используйте предварительно обработанные входные тензоры, прикрепленные как метаданные, вместо предварительной обработки внутри плагина. Если этот параметр установлен, убедитесь, что размер пакета nvinfer равен сумме ROI, установленных в файле конфигурации плагина gst-nvdspreprocess.
  #input-tensor-from-meta: 1

  ##(All, Both, Integer, действительные значения см. в перечислении NvBufSurfTransform_Inter в nvbufsurftransform.h.) Фильтр, используемый для масштабирования кадров/обрезок объектов до сетевого разрешения (игнорируется, если включен input-tensor-meta).
  scaling-filter: 1



  #############################################################################
  #_________________________ MODEL COMMON PATH AND LIBS
  #############################################################################
  ##(All, Both, String) Путь к файлу модели ONNX
  onnx-file: ../models/Primary_Detector/current_model.onnx

  ##(All, Both, String) Путь к модели, закодированной набором инструментов TAO.
  #tlt-encoded-model: /home/ubuntu/model.etlt

  ##(All, Both, String) Ключ для модели, закодированной в наборе инструментов TAO.
  #tlt-model-key: abc

  ##(All, Both, String) Путь к файлу механизма сериализованной модели
  model-engine-file: ../models/Primary_Detector/current_model.onnx_b2_gpu0_fp16.engine

  ##(All, Both, String) Имя пользовательской функции создания TensorRT CudaEngine. Подробности см. в разделе «Интерфейс реализации пользовательской модели».
  #engine-create-func-name: NvDsInferYoloCudaEngineGet

  ##(All, Both, String) Путь к файлу средних данных в формате PPM (игнорируется, если включен input-tensor-meta)
  #mean-file: /home/ubuntu/model_meanfile.ppm

  ##(All, Both, String) Путь к файлу модели. Не требуется, если используется файл model-engine.
  #model-file: /home/ubuntu/model

  ##(All, Both, String) Путь к файлу prototxt. Не требуется, если используется файл model-engine.
  #proto-file: /home/ubuntu/model.prototxt

  ##(All, Both, String) Абсолютный путь к библиотеке, содержащей реализации пользовательских методов для пользовательских моделей.
  #custom-lib-path: /home/ubuntu/libresnet_custom_impl.so

  ##(All,Both, String) Путь к файлу конфигурации для пользовательских сетей, доступный в пользовательском интерфейсе для создания механизмов CUDA.
  #custom-network-config: /home/ubuntu/network.config

  ##(All, Both, Integer,) Формат данных, который будет использоваться путем вывода
  #  0:FP32, 
  #  1:INT8, 
  #  2:FP16, 
  #  3:BEST
  network-mode: 2

  ##(All, Both, String) Путь к калибровочному файлу INT8 для регулировки динамического диапазона модели FP32.
  #int8-calib-file: /home/ubuntu/int8_calib

  ##(All, Both, Integer, >0) Размер рабочей области, которая будет использоваться движком, в МБ
  #workspace-size: 45

  ##(All, Primary, Integer, >0) Указывает количество последовательных пакетов, которые будут пропущены для вывода.
  interval: 1

  ##(All, Both, Integer, >0) Размер метапула выходного тензора
  #tensor-meta-pool-size: 20

  ##(All, Both, Boolean) Gst-nvinfer присоединяет необработанные выходные данные тензора как метаданные Gst Buffer.
  output-tensor-meta: 1

  ##(All, Both) Указывает тип данных и порядок связанных выходных слоев. Для неуказанных слоев по умолчанию используются FP32 и CHW.
  #Semi-colon separated list of format. <output-layer1-name>:<data-type>:<order>;<output-layer2-name>:<data-type>:<order>) 
  # data-type should be one of [fp32, fp16, int32, int8]
  # order should be one of [chw, chw2, chw4, hwc8, chw16, chw32]
  #output-io-formats: conv2d_bbox:fp32:chw;conv2d_cov/Sigmoid:fp32:chw

  ##(All, Both) Указывает тип устройства и точность для любого уровня в сети.
  #Semi-colon separated list of format. 
  # <layer1-name>:<precision>:<device-type>;<layer2-name>:<precision>:<device-type>;) 
  # precision should be one of [fp32, fp16, int8]
  # Device-type should be one of [gpu, dla]
  #layer-device-precision: output_cov/Sigmoid:fp32:gpu;output_bbox/BiasAdd:fp32:gpu;




  #############################################################################
  #_________________________ CLASSES
  #############################################################################
  ##**(Detector, Both, Integer, >0) Количество классов, обнаруженных сетью
  num-detected-classes: 2

  ##(All, Both, Semicolon delimited integer array) Идентификаторы классов родительского GIE, над которыми должен работать этот GIE.
  # Работает с объектами с идентификаторами классов 1, 2, созданными родительским GIE. Если для идентификатора класса установлено значение -1, он будет работать со всеми идентификаторами классов.
  # если -1, то выдает ошибку vector::_M_range_check: __n (which is 18446744073709551615) >= this->size() (which is 0)
  operate-on-class-ids: 1;2   
  #operate-on-class-ids: 

  ##(2, Semicolon delimited integer array) Отфильтровать обнаруженные объекты, принадлежащие указанным идентификаторам классов.
  #filter-out-class-ids: 1




  #############################################################################
  #_________________________ Classifier
  #############################################################################
  ##**(Classifier, Both, Float, ≥0) Вероятность минимальной пороговой метки. GIE выводит метку с наибольшей вероятностью, если она превышает этот порог.
  #classifier-threshold: 0.4

  ##(Classifier, Both, String ) Описание того, что делает классификатор
  #(alphanumeric, ‘-’ and ‘_’ allowed, no spaces)
  #classifier-type: vehicletype

  ##(Classifier, Secondary, Boolean) Позволяет делать выводы по обнаруженным объектам и асинхронным вложениям метаданных. Работает только тогда, когда прикреплены идентификаторы трекера. Направляет буфер вниз по течению, не дожидаясь результатов вывода. Прикрепляет метаданные после того, как результаты вывода станут доступны следующему Gst-буферу в его внутренней очереди.
  #classifier-async-mode: 1
  

  ##(Detector & Classifier, Secondary, Integer, ≥0) Интервал повторного вывода для объектов в кадрах
  #secondary-reinfer-interval: 15

  ##(Classifier, Both, String) Имя функции синтаксического анализа выходных данных пользовательского классификатора. Если не указано, Gst-nvinfer использует внутреннюю функцию анализа слоев softmax.
  #parse-classifier-func-name: parse_bbox_softmax

  ##(Detector & classifier, Both, String) Путь к текстовому файлу, содержащему метки модели.
  #labelfile-path: /home/ubuntu/model_labels.txt


  
  #############################################################################
  #_________________________DETECTOR
  #############################################################################
  ##(Detector, Both, Integer ) Используемый алгоритм кластеризации. Обратитесь к следующей таблице для настройки конкретных параметров алгоритма. Дополнительную информацию см. в разделе «Алгоритмы кластеризации, поддерживаемые nvinfer».
  # https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvinfer.html#cluster-mode-info
  # 0: OpenCV groupRectangles() 
  # 1: DBSCAN 
  # 2: Non Maximum Suppression 
  # 3: DBSCAN + NMS Hybrid 
  # 4: No clustering
  cluster-mode: 4 #for instance segmentation

  ##(Detector, Both, Boolean) Указывает, использовать ли DBSCAN или функцию OpenCV groupRectangles() для группировки обнаруженных объектов. УСТАРЕЛО. Вместо этого используйте режим кластера.
  #enable-dbscan: 1
  ##(Detector, Both, Boolean) Обрежьте ограничивающие рамки объекта так, чтобы они соответствовали указанной границе области интереса.
  #crop-objects-to-roi-boundary: 1

  ##(Detector, Both, String) Имя функции синтаксического анализа пользовательской ограничивающей рамки. Если не указано, Gst-nvinfer использует внутреннюю функцию для модели resnet, предоставляемую SDK.
  #parse-bbox-func-name: parse_bbox_resnet

  ##(Detector & Classifier, Secondary, Integer, ≥0) Интервал повторного вывода для объектов в кадрах
  #secondary-reinfer-interval: 15
  
  ##(Detector & classifier, Both, String) Путь к текстовому файлу, содержащему метки модели.
  #labelfile-path: /home/ubuntu/model_labels.txt


  ###############################################################################
  #_______________________SEGMENTATION
  ###############################################################################
  # example https://github.com/NVIDIA-AI-IOT/deepstream_python_apps/blob/master/apps/deepstream-segmentation/dstest_segmentation_config_industrial.txt
  ##**(Segmentation, Instance segmentation, Both, Float, ≥0.0) Порог уверенности для модели сегментации для вывода допустимого класса для пикселя. Если достоверность меньше этого порога, выходные данные класса для этого пикселя равны -1.
  segmentation-threshold: 0.00

  ##(Segmentation, Both, Integer, ) Порядок выходного слоя сети сегментации
  # https://oneapi-src.github.io/oneDNN/dev_guide_understanding_memory_formats.html
  # 0:NCHW, партия N , каналы C , глубина D , высота H , ширина W
  # 1:NHWC
  segmentation-output-order: 0

  ##(Instance Segmentation, Primary, String) Имя пользовательской функции анализа сегментации экземпляра. Это обязательно, например, сеть сегментации, поскольку здесь нет внутренней функции.
  #parse-bbox-instance-mask-func-name: NvDsInferParseCustomMrcnnTLT

  ##(Instance Segmentation, Primary, Boolean) Gst-nvinfer присоединяет выходные данные маски экземпляра к метаданным объекта.
  #output-instance-mask: 1


  #############################################################################
  #_________________________ Secondary
  #############################################################################
  ##(All, Secondary, Integer, ≥0) Вторичный GIE делает вывод только об объектах с этой минимальной шириной.
  #input-object-min-width: 40

  ##(All, Secondary, Integer, ≥0) Вторичный GIE делает вывод только об объектах с этой минимальной высотой.
  #input-object-min-height: 40

  ##(All, Secondary, Integer, ≥0) Вторичный GIE делает вывод только об объектах с этой максимальной шириной.
  #input-object-max-width: 256 #(0 disables the threshold)


  ##(All, Both, Integer, ≥0) Вторичный GIE делает вывод только об объектах с этой максимальной высотой.
  #input-object-max-height: 256

  ##(Detector & Classifier, Secondary, Integer, ≥0) Интервал повторного вывода для объектов в кадрах
  #secondary-reinfer-interval: 15

  output-blob-names: final_conv/BiasAdd






## Группа настраивает параметры обнаружения для всех классов. 
## https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvinfer.html#gst-nvinfer-file-configuration-specifications
class-attrs-all:
  ##(Object detector, Both, Integer, ≥0) Смещение области интереса от верхней части кадра. Выводятся только объекты внутри области интереса.
  roi-top-offset: 0
  roi-bottom-offset: 0
  ## Минимальная ширина в пикселях обнаруженных объектов, выводимых GIE
  detected-min-w: 0
  detected-min-h: 0
  detected-max-w: 0
  detected-max-h: 0
 

#Use the config params below for dbscan clustering mode
#class-attrs-all:
  #detected-min-w: 4
  #detected-min-h: 4
  #minBoxes: 3

#Use the config params below for NMS clustering mode
# class-attrs-all:
#   topk: 20
#   nms-iou-threshold: 0.5
#   pre-cluster-threshold: 0.2

# Per class configurations
## Группа [class-attrs-<class-id>]настраивает параметры обнаружения для класса, указанного с помощью <class-id> 
## https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvinfer.html#id3
#class-attrs-0:
  ##(Object detector, Both, Float, ≥0) Порог обнаружения
  #threshold: 0.5

  ##(Object detector, Both, Float, ≥0) Порог обнаружения, который будет применяться перед операцией кластеризации
  #pre-cluster-threshold: 0.5

  ##(Object detector, Both, Float, ≥0) Порог обнаружения, который будет применяться после операции кластеризации
  #post-cluster-threshold: 0.5

  ##(Object detector, Both, Float, ≥0) Значения Epsilon для функции OpenCV grouprectangles() и алгоритма DBSCAN
  #eps: 0.2

  ##(Object detector, Both, Integer, ≥0) Пороговое значение для слияния прямоугольников для функции OpenCV grouprectangles
  #group-threshold: 1 #(0 disables the clustering functionality)

  ##(Object detector, Both, Integer, ≥0) Минимальное количество точек, необходимое для формирования плотной области для алгоритма DBSCAN.
  #minBoxes: 1 #(0 disables the clustering functionality)

  ##(Object detector, Both, Float, ≥0) Минимальная сумма доверия всех соседей в кластере, чтобы он считался действительным кластером.
  #dbscan-min-score: 0.7

  ##(Object detector, Both, Float, ≥0) Максимальный балл IOU между двумя предложениями, после которого предложение с более низкой достоверностью будет отклонено.
  #nms-iou-threshold: 0.2

  ##(Object detector, Both, Integer, ≥0) Смещение области интереса от верхней части кадра. Выводятся только объекты внутри области интереса.
  #roi-top-offset: 2

  ##(Object detector, Both, Integer, ≥0) Смещение области интереса от нижней части кадра. Выводятся только объекты внутри области интереса.
  #roi-bottom-offset: 2

  ##(Object detector, Both, Integer, ≥0) Минимальная ширина в пикселях обнаруженных объектов, выводимых GIE
  #detected-min-w: 64

  ##(Object detector, Both, Integer, ≥0) Минимальная высота обнаруженных объектов в пикселях, выводимых GIE
  #detected-min-h: 64

  ##(Object detector, Both, Integer, ≥0) Максимальная ширина в пикселях обнаруженных объектов, выводимых GIE
  #detected-max-w: 0 #(0 disables the property)

  ##(Object detector, Both, Integer, ≥0) Максимальная высота обнаруженных объектов в пикселях, выводимых GIE
  #detected-max-h: 0 #(0 disables the property)

  ##(Object detector, Both , Integer, ≥0. -1 to disable) Сохраняйте только первые K объектов с наивысшими показателями обнаружения.
  #topk: 10


# class-attrs-1:
#   pre-cluster-threshold: 0.05
#   eps: 0.7
#   dbscan-min-score: 0.5

#class-attrs-2:
  #pre-cluster-threshold: 0.1
  #eps: 0.6
  #dbscan-min-score: 0.95

#class-attrs-3:
  #pre-cluster-threshold: 0.05
  #eps: 0.7
  #dbscan-min-score: 0.5

